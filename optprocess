#set anchor values : # of anchors = 2 * # of parcel
def anchors(series,n_parcels=20):
  anchors = pd.Series(map(lambda x: series.quantile(q=x), np.arange(n_parcels * 2) + 1),index=np.arange(n_parcels * 2),name=''.join([series.name,'_Anchors']))
  return anchors

#data point range for parcelized categorization
def sigma(series,n_parcels=20):
  sigma = (series.max() - series.min())/(2*n_parcels)
  return sigma

#angle of movement
def theta(data): #data is slice beginning with size of period, perhaps better to structure process differently to calculate theta for many periods  simultaneously
  theta = np.max(abs(data['high'].max()-data.ix[0]['open']),(abs(data['low'].min()-data.ix[0]['open'])))/len(data)
  return theta

#directionality
def phi(data):
  if abs(data['high'].max()-data.ix[0]['open']) > abs(data['low'].min()-data.ix[0]['open']):  
    phi = abs(data['high'].max()-data.ix[0]['open'])/abs(data['low'].min()-data.ix[0]['open'])
  elif abs(data['high'].max()-data.ix[0]['open']) < abs(data['low'].min()-data.ix[0]['open']):
    phi = -1*(abs(data['low'].min()-data.ix[0]['open'])/abs(data['high'].max()-data.ix[0]['open']))
  else:
    phi = 1
  return phi
  
#volatility -- can measure number of swings (alpha) or violence of swings (beta) -- Requires data length of 2-3+
def mu(data):
  high_swings: 2-3 day linear fit of high values count # of positive/negative switches
  low_swings: " "
  beta = max(abs(high_swings.max()),abs(low_swings.min())
  alpha_mu = average of the two?
  return alpha, beta

#indication prep process
indication_df = pd.DataFrame(index=np.arange(100))
indication_dict = {}
for indication in data_calcs.columns:
  indication_dict[indication][0] = data[indication].dtype
  if indication_dict[indication][0].str.contains('float'):
    indication_dict[indication][1] = sigma(data[indication],n_parcels=20)
    indication_df = pd.concat([indication_df,anchors(data[indication],n_parcels=20)],axis=1)
  else:
    indication_dict[indication][1] = 0
    
    
import itertools as it

#import chain, combinations, product
def all_subsets(ss):
  subsets = pd.Seies(chain(*map(lambda x: combinations(ss, x), range(0, len(ss)+1))),name='Subsets_' + dt.datetime.today().date() 
  return subsets
  
max_combo_length = 5?
base_report_columns = ['Combo','Combo_Values','Theta_(Angle)','Phi_(Directionality)','Alpha_Mu_(Volatility-#_of_Swings)','Beta_Mu_(Violence_of_Swings)']
#broadcast 'Combo','Combo_Values' into DF to be joined with base report
#get subsets of indications
base_report_df = pd.DataFrame(index=?Unknown value TBD?, columns=base_report_columns)

indication_combos = all_subsets(data)
i = 0 
for combo in indication_combos:
  sorted_df = raw_df
  if len(combo) < max_combo_length:   
    for value in indication_df[combo[0]]:
      combo_values = map(lambda indic: indication_df[indic],combo[1:])
      value_combinations = it.product([value,combo_values], len(combo))
      
      for comval in value_combinations:
        for val in comval:
          for x in np.arange(len(combo)):
            if indic_data.columns.isin(combo[x]):
              base_report_df.at[i,combo[x]] = val
          if val.dtype.str.contains('float'):
            sorted_df = sorted_df[sorted_df[indic] < val + indication_dict[indication][1]] & sorted_df[sorted_df[indic] > val - indication_dict[indication][1]]
          else:
            sorted_df = sorted_df[sorted_df[indic] == val]
        if len(sorted_df) < 5:
          base_report_df.at[i,'Indication_Combination'] = combo
          base_report_df.at[i,'Combo_Values'] = comval
          base_report_df.iloc[i]['Theta_(Angle)','Phi_(Directionality)','Alpha_Mu_(Volatility-#_of_Swings)','Beta_Mu_(Violence_of_Swings)'] = np.nan
          null row base_report
          continue
        else: 
          #run analsis --> copy to base_report_df
          for d in sorted_df.index
            price_data = raw_data.ix[d:raw_data.Index.get_loc(d) + period]['Open','High','Low','Close']
            th = theta(price_data)
            ph = theta(price_data)
            a_my, b_my = mu(price_data)          
            comval_thetas = comval_thetas.append(th)
            comval_phis =  comval_phis.append(ph)
            comval_alpha_mus = comval_alpha_mus.append(a_my)
            comval_beta_mus = comval_beta_mus.append(b_my)

          the_c = comval_thetas.mean()
          phi_c = comval_phis.mean()
          alph_mu_c = comval_alpha_mus.mean()
          beta_mu_c =  comval_beta_mus.mean()     
          base_report_df.at[i,'Indication_Combination'] = combo
          base_report_df.at[i,'Combo_Values'] = comval
          base_report_df.at[i,'Theta_(Angle)'] = the_c
          base_report_df.at[i,'Phi_(Directionality)'] = phi_c
          base_report_df.at[i,'Alpha_Mu_(Volatility-#_of_Swings)'] = alph_mu_c
          base_report_df.at[i,'Beta_Mu_(Violence_of_Swings)'] = beta_mu_c
          i = i + 1
report_indications = base_report[indic_data.columns]
report_theta = (base_report[base_report['Theta_(Angle)'] >= base_report['Theta_(Angle)'].quantile(q=.95)])
report_theta['Criteria'] = 'Theta'
report_phi = (base_report[base_report['Phi_(Directionality)'] >= abs(base_report['Phi_(Directionality)']).quantile(q=.95)])
report_phi['Criteria' = 'Phi'
report_alpha_mu = (base_report[base_report['Alpha_Mu_(Volatility-#_of_Swings)'] >= base_report['Alpha_Mu_(Volatility-#_of_Swings)'].quantile(q=.95)])
report_alpha_mu['Criteria'] = 'Alpha_Mu'
report_beta_mu = (base_report[base_report['Beta_Mu_(Volatility-#_of_Swings)'] >= base_report['Beta_Mu_(Volatility-#_of_Swings)'].quantile(q=.95)])
report_beta_mu['Criteria'] = 'Beta_Mu'
report = pd.concat([report_indications,report_theta,report_phi,report_alpha_mu,report_beta_mu],axis=0)
report.to_csv(reportpath,index=True,headers=report.columns)

        
        
        
            
      
      
  
#estimate # of possible combinations to be tested

#need to order combination process
  #how?
    #1) indexing: could codify each combination, assign a number and then cycle through the range containing all numbers
    #2) elimination: could run all combinations with a 'base' indication and then when finished proceed to the next 'base' indication having removed the prior from the pool of indications


#float anchoring and filtering process
#generate anchors as series of 00.00 floats
#use sigma to generate filter
#apply filter


#generate combination codes
#run through each code

Analyzed Indicators:
Floats:
  Fully Parcelized 40-anchors:
    14d CCI
    20d CCI
    14d %K
    3d  %D
    20/2 Bollinger Rank
    20/2 Keltner Rank
    20 RSI
    
  Minimally Parcelized 20-anchors:
    5d  SMA Norm
    14d SMA Norm
    20d SMA Norm
    50d SMA Norm
    100d SMA Norm
    200d SMA Norm
    5d  EMA Norm
    14d EMA Norm
    20d EMA Norm
    50d EMA Norm
    100d EMA Norm
    200d EMA Norm

  
  
  

  
Discrete:
  14d-5d CCI-Div-+
  14d-8d CCI-Div-+
  14d-13d CCI-Div-+
  20d-5d CCI-Div-+
  20d-8d CCI-Div-+
  20d-13d CCI-Div-+
  14d-5d CCI-Div--
  14d-8d CCI-Div--
  14d-13d CCI-Div--
  20d-5d CCI-Div--
  20d-8d CCI-Div--
  20d-13d CCI-Div--
  
  K-D Positive/Negative?
  20 RSI Div +
  20 RSI Div -
  10d MACD Div +
  10d MACD Div -
  10d MACD Div +
  10d MACD Div -
  
Boolean:  
  5/14 SMA Crossover
  14/20 SMA Crossover
  50/100 SMA Crossover
  100/200 SMA Crossover
  5/14 SMA Crossunder
  14/20 SMA Crossunder
  50/100 SMA Crossunder
  100/200 SMA Crossunder
  5/14 SMA Over
  14/20 SMA Over
  50/100 SMA Over
  100/200 SMA Over
  5/14 SMA Under
  14/20 SMA Under
  50/100 SMA Under
  100/200 SMA Under
  5/14 EMA Crossover
  14/20 EMA Crossover
  50/100 EMA Crossover
  100/200 EMA Crossover
  5/14 EMA Crossunder
  14/20 EMA Crossunder
  50/100 EMA Crossunder
  100/200 EMA Crossunder
  5d Blowest
  10d Blowest
  20d Blowest
  50d Blowest
  100d Blowest
  200d Blowest
  5d HHighest
  10d HHighest
  20d HHighest
  50d HHighest
  100d HHighest
  200d HHighest
  
  
Possible:
  Candlesticks:
    Doji
    Hammer/Hangman
    
    
  
