#set anchor values : # of anchors = 2 * # of parcel
def anchors(series,n_parcels=20):
  anchors = pd.Series(map(lambda x: series.quantile(q=x), np.arange(n_parcels * 2) + 1),index=np.arange(n_parcels * 2),name=''.join([series.name,'_Anchors']))
  return anchors

#data point range for parcelized categorization
def sigma(series,n_parcels=20):
  sigma = (series.max() - series.min())/(2*n_parcels)
  return sigma

#angle of movement
def theta(data): #data is slice beginning with size of period, perhaps better to structure process differently to calculate theta for many periods  simultaneously
  theta = np.max(abs(data['high'].max()-data.ix[0]['open']),(abs(data['low'].min()-data.ix[0]['open'])))/len(data)
  return theta

#directionality
def phi(data):
  if abs(data['high'].max()-data.ix[0]['open']) > abs(data['low'].min()-data.ix[0]['open']):  
    phi = abs(data['high'].max()-data.ix[0]['open'])/abs(data['low'].min()-data.ix[0]['open'])
  elif abs(data['high'].max()-data.ix[0]['open']) < abs(data['low'].min()-data.ix[0]['open']):
    phi = -1*(abs(data['low'].min()-data.ix[0]['open'])/abs(data['high'].max()-data.ix[0]['open']))
  else:
    phi = 1
  return phi
  
#volatility -- can measure number of swings (alpha) or violence of swings (beta) -- Requires data length of 2-3+
def mu(data):
  high_swings: 2-3 day linear fit of high values count # of positive/negative switches
  low_swings: " "
  beta = max(abs(high_swings.max()),abs(low_swings.min())
  alpha_mu = average of the two?
  return alpha, beta

#indication prep process
indication_df = pd.DataFrame(index=np.arange(100))
indication_dict = {}
for indication in data_calcs.columns:
  indication_dict[indication][0] = data[indication].dtype
  if indication_dict[indication][0].str.contains('float'):
    indication_dict[indication][1] = sigma(data[indication],n_parcels=20)
    indication_df = pd.concat([indication_df,anchors(data[indication],n_parcels=20)],axis=1)
  else:
    indication_dict[indication][1] = 0
    
    
import itertools as it

#import chain, combinations, product
def all_subsets(ss):
  subsets = pd.Seies(chain(*map(lambda x: combinations(ss, x), range(0, len(ss)+1))),name='Subsets_' + dt.datetime.today().date() 
  return subsets
  
max_combo_length = 5?
base_report_columns = ['Combo','Combo_Values','Theta_(Angle)','Phi_(Directionality)','Alpha_Mu_(Volatility-#_of_Swings)','Beta_Mu_(Violence_of_Swings)']
#broadcast 'Combo','Combo_Values' into DF to be joined with base report
#get subsets of indications
base_report_df = pd.DataFrame(index=?Unknown value TBD?, columns=base_report_columns)

indication_combos = all_subsets(data)
i = 0 
for combo in indication_combos:
  sorted_df = raw_df
  if len(combo) < max_combo_length:   
    for value in indication_df[combo[0]]:
      combo_values = map(lambda indic: indication_df[indic],combo[1:])
      value_combinations = it.product([value,combo_values], len(combo))
      
      for comval in value_combinations:
        for val in comval:
          if val.dtype.str.contains('float'):
            sorted_df = sorted_df[sorted_df[indic] < val + indication_dict[indication][1]] & sorted_df[sorted_df[indic] > val - indication_dict[indication][1]]
          else:
            sorted_df = sorted_df[sorted_df[indic] == val]
        #run analsis --> copy to base_report_df
        for d in sorted_df.index
          price_data = raw_data.ix[d:raw_data.Index.get_loc(d) + period]['Open','High','Low','Close']
          th = theta(price_data)
          ph = theta(price_data)
          a_my, b_my = mu(price_data)          
          comval_thetas = comval_thetas.append(th)
          comval_phis =  comval_phis.append(ph)
          comval_alpha_mus = comval_alpha_mus.append(a_my)
          comval_beta_mus = comval_beta_mus.append(b_my)
          
        the_c = comval_thetas.mean()
        phi_c = comval_phis.mean()
        alph_mu_c = comval_alpha_mus.mean()
        beta_mu_c =  comval_beta_mus.mean()     
        base_report_df.at[i,'Indication_Combination'] = combo
        
        base_report_df.at[i,'Combo_Values'] = comval
        base_report_df.at[i,'Theta_(Angle)'] = the_c
        base_report_df.at[i,'Phi_(Directionality)'] = phi_c
        base_report_df.at[i,'Alpha_Mu_(Volatility-#_of_Swings)'] = alph_mu_c
        base_report_df.at[i,'Beta_Mu_(Violence_of_Swings)'] = beta_mu_c
        i = i + 1
report_theta = (base_report[base_report['Theta_(Angle)'] >= base_report['Theta_(Angle)'].quantile(q=.95)])
report_theta['Criteria'] = 'Theta'
report_phi = (base_report[base_report['Phi_(Directionality)'] >= abs(base_report['Phi_(Directionality)']).quantile(q=.95)])
report_phi['Criteria' = 'Phi'
report_alpha_mu = (base_report[base_report['Alpha_Mu_(Volatility-#_of_Swings)'] >= base_report['Alpha_Mu_(Volatility-#_of_Swings)'].quantile(q=.95)])
report_alpha_mu['Criteria'] = 'Alpha_Mu'
report_beta_mu = (base_report[base_report['Beta_Mu_(Volatility-#_of_Swings)'] >= base_report['Beta_Mu_(Volatility-#_of_Swings)'].quantile(q=.95)])
report_beta_mu['Criteria'] = 'Beta_Mu'
report = pd.concat([indic_data,report_theta,report_phi,report_alpha_mu,report_beta_mu],axis=0)
report.to_csv(reportpath,index=True,headers=report.columns)

        
        
        
            
      
      
  
#estimate # of possible combinations to be tested

#need to order combination process
  #how?
    #1) indexing: could codify each combination, assign a number and then cycle through the range containing all numbers
    #2) elimination: could run all combinations with a 'base' indication and then when finished proceed to the next 'base' indication having removed the prior from the pool of indications


#float anchoring and filtering process
#generate anchors as series of 00.00 floats
#use sigma to generate filter
#apply filter


#generate combination codes
#run through each code
  
    
  
