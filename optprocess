#set anchor values : # of anchors = 2 * # of parcel
def anchors(series,n_parcels=20):
  anchors = pd.Series(map(lambda x: series.quantile(q=x), np.arange(n_parcels * 2) + 1),index=np.arange(n_parcels * 2),name=''.join([series.name,'_Anchors']))
  return anchors

#data point range for parcelized categorization
def sigma(series,n_parcels=20):
  sigma = (series.max() - series.min())/(2*n_parcels)
  return sigma

#angle of movement
def theta(data): #data is slice beginning with size of period, perhaps better to structure process differently to calculate theta for many periods  simultaneously
  theta = np.max(abs(data['high'].max()-data.ix[0]['open']),(abs(data['low'].min()-data.ix[0]['open'])))/len(data)
  return theta

#directionality
def phi(data):
  if abs(data['high'].max()-data.ix[0]['open']) > abs(data['low'].min()-data.ix[0]['open']):  
    phi = abs(data['high'].max()-data.ix[0]['open'])/abs(data['low'].min()-data.ix[0]['open'])
  elif abs(data['high'].max()-data.ix[0]['open']) < abs(data['low'].min()-data.ix[0]['open']):
    phi = -1*(abs(data['low'].min()-data.ix[0]['open'])/abs(data['high'].max()-data.ix[0]['open']))
  else:
    phi = 0
  return phi
  
#volatility -- can measure number of swings (alpha) or violence of swings (beta) -- Requires data length of 2-3+
def mu(data):
  high_swings: 2-3 day linear fit of high values count # of positive/negative switches
  low_swings: " "
  beta = max(abs(high_swings.max()),abs(low_swings.min())
  alpha_mu = average of the two?
  return alpha, beta

#indication prep process
indication_df = pd.DataFrame(index=np.arange(100))
indication_dict = {}
for indication in data_calcs.columns:
  indication_dict[indication][0] = data[indication].dtype
  if indication_dict[indication][0].str.contains('float'):
    indication_dict[indication][1] = sigma(data[indication],n_parcels=20)
    indication_df = pd.concat([indication_df,anchors(data[indication],n_parcels=20)],axis=1)
  else:
    indication_dict[indication][1] = 0
    
    
from itertools import chain, combinations
def all_subsets(ss):
  subsets = pd.Seies(chain(*map(lambda x: combinations(ss, x), range(0, len(ss)+1))),name='Subsets_' + dt.datetime.today().date() 
  return subsets
  
max_combo_length = 5?

#get subsets of indications
indication_combos = all_subsets(data)
for combo in indication_combos:
  if len(combo) < max_combo_length:   
    for value in indication_df[combo[0]]:
      combo_values = map(lambda indic: indication_df[indic],combo[1:])
      value_combinations = combinations([value,combo_values], len(combo))
      
      for comval in value_combinations:
        for val in comval:
          if val.dtype.str.contains('float'):
            indication_dict[indication][1]
          
      
      
  
#estimate # of possible combinations to be tested

#need to order combination process
  #how?
    #1) indexing: could codify each combination, assign a number and then cycle through the range containing all numbers
    #2) elimination: could run all combinations with a 'base' indication and then when finished proceed to the next 'base' indication having removed the prior from the pool of indications


#float anchoring and filtering process
#generate anchors as series of 00.00 floats
#use sigma to generate filter
#apply filter


#generate combination codes
#run through each code
  
    
  
